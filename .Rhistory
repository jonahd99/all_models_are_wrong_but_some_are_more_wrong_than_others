# Data frame that only contains observations from athletes with enough intial #
# training data                                                               #
###############################################################################
df_power_of_10 %>%
filter(id %in% ID_enough_train_init & distance >= 1500)  -> training_data_init
###############################################################################
# For each athlete, create a dataset that contains duplicated training        #
# observations depending on the number of marathons completed by the athelte  #
###############################################################################
duplicated_training_data <- tibble()
re_wrangle <- FALSE
if(re_wrangle == TRUE){
for(i in 1:length(ID_enough_train_init)){
ID <- ID_enough_train_init[i]
n_marathons <- df_n_marathons %>%
filter(id == ID) %>%
pull(n_marathons)
df_i <- training_data_init %>%
filter(id == ID)
aux_marathon_n <- rep(1:n_marathons, each = nrow(df_i))
duplicated_training_data_aux <- df_i %>%
slice(rep(1:n(), times = n_marathons)) %>%
cbind(marathon_n = aux_marathon_n) %>%
mutate(updated_id = paste0(id, "_", marathon_n))
duplicated_training_data <- rbind(duplicated_training_data,duplicated_training_data_aux)
}
saveRDS(duplicated_training_data,here("data","duplicated_training_data.RDS"))
}else{
duplicated_training_data <- readRDS(here("data","duplicated_training_data.RDS"))
}
###############################################################################
# Getting the IDs for the athletes that now have enough training data within  #
# the 4 months prior to the testing marathon                                  #
###############################################################################
marathons_only %>%
select(updated_id,date_lb,date_up) %>%
left_join(duplicated_training_data, by = c("updated_id"), multiple = "all") %>%
mutate(is_in = if_else(date >= date_lb & date < date_up,1,0)) %>%
filter(is_in == 1 & distance >= 1500) %>%
group_by(updated_id) %>%
summarise(n_dis = n_distinct(distance),
n_train = n()) %>%
filter(n_dis >= 3 & n_train >= 3) %>%
pull(updated_id) %>%
unique() -> ID_final
###############################################################################
# Creating the final training dataset                                         #
###############################################################################
marathons_only %>%
select(updated_id,date_lb,date_up, duration, power, marathon_n) %>%
rename(act_duration = duration,
act_velocity = power) %>%
left_join(duplicated_training_data, by = c("updated_id","marathon_n"), multiple = "all") %>%
mutate(is_in = if_else(date >= date_lb & date < date_up,1,0)) %>%
filter(is_in == 1 & updated_id %in% ID_final) -> training_data
###############################################################################
# Get the Endurance parameter for the PL model                                #
###############################################################################
get_E <- function(power,durations){
data_pl <- tibble(power = power, durations = durations)
pl_lr <- lm(data = data_pl, I(log(power)) ~ I(log(durations)))
b <- 1 - as.numeric(-coef(pl_lr)[2])
return(b)
}
###############################################################################
# Get the Sprint parameter for the PL model                                   #
###############################################################################
get_S <- function(power,durations){
data_pl <- tibble(power = power, durations = durations)
pl_lr <- lm(data = data_pl, I(log(power)) ~ I(log(durations)))
a <- as.numeric(exp(coef(pl_lr)[1]))
return(a)
}
###############################################################################
# Creating a data frame of the actual finishing time for each marathon        #
###############################################################################
marathons_only %>%
select(updated_id,duration) %>%
rename(mar_fin_time = duration) -> marathon_fin_time_df
###############################################################################
# Calculating the error for each marathon                                     #
###############################################################################
training_data %>%
group_by(updated_id) %>%
mutate(weighting = 1/as.numeric(date_up - date)) %>%
summarise(E = get_E(power = power, durations = duration),
S = get_S(power = power, durations = duration)) %>%
filter(E <= 1 & E > 0) %>%
mutate(mar_fin = (42194.988/S)^(1/(E)),
mar_fin_w = (42194.988/S_w)^(1/(E_w))) %>%
left_join(marathon_fin_time_df, by = "updated_id") %>%
mutate(error = abs(mar_fin - mar_fin_time)/ mar_fin_time,
error_w = abs(mar_fin_w - mar_fin_time)/ mar_fin_time) -> error_df
training_data %>%
group_by(updated_id) %>%
mutate(weighting = 1/as.numeric(date_up - date)) %>%
summarise(E = get_E(power = power, durations = duration),
S = get_S(power = power, durations = duration)) %>%
filter(E <= 1 & E > 0) %>%
mutate(mar_fin = (42194.988/S)^(1/(E))) %>%
left_join(marathon_fin_time_df, by = "updated_id") %>%
mutate(error = abs(mar_fin - mar_fin_time)/ mar_fin_time) -> error_df
###############################################################################
# Average error                                                               #
###############################################################################
mean(error_df$error, na.rm = TRUE)
training_data %>%
group_by(updated_id) %>%
mutate(weighting = 1/as.numeric(date_up - date)) %>%
summarise(E = get_E(power = power, durations = duration),
S = get_S(power = power, durations = duration)) %>%
# filter(E <= 1 & E > 0) %>% # Out of bounds for the E parameter -- 14/1697 marathons removed
mutate(mar_fin = (42194.988/S)^(1/(E))) %>%
left_join(marathon_fin_time_df, by = "updated_id") %>%
mutate(error = abs(mar_fin - mar_fin_time)/ mar_fin_time) -> error_df
################################################################################
# Preamble                                                                     #
################################################################################
library("here")
library("tidyverse")
training_data %>%
group_by(updated_id) %>%
mutate(weighting = 1/as.numeric(date_up - date)) %>%
summarise(E = get_E(power = power, durations = duration),
S = get_S(power = power, durations = duration)) %>%
# filter(E <= 1 & E > 0) %>% # Out of bounds for the E parameter -- 14/1697 marathons removed
mutate(mar_fin = (42194.988/S)^(1/(E))) %>%
left_join(marathon_fin_time_df, by = "updated_id") %>%
mutate(error = abs(mar_fin - mar_fin_time)/ mar_fin_time) -> error_df
###############################################################################
# Average error for N =  1683                                                 #
###############################################################################
mean(error_df$error, na.rm = TRUE)
training_data %>%
group_by(updated_id) %>%
mutate(weighting = 1/as.numeric(date_up - date)) %>%
summarise(E = get_E(power = power, durations = duration),
S = get_S(power = power, durations = duration)) %>%
filter(E <= 1 & E > 0) %>% # Out of bounds for the E parameter -- 14/1697 marathons removed
mutate(mar_fin = (42194.988/S)^(1/(E))) %>%
left_join(marathon_fin_time_df, by = "updated_id") %>%
mutate(error = abs(mar_fin - mar_fin_time)/ mar_fin_time) -> error_df
###############################################################################
# Average error for N =  1683                                                 #
###############################################################################
mean(error_df$error, na.rm = TRUE)
################################################################################
# Read me                                                                      #
################################################################################
################################################################################
# Preamble                                                                     #
################################################################################
library("here")
library("tidyverse")
################################################################################
# Blythe and Kiraly (2016) -- Running dataset                                  #
################################################################################
df_power_of_10 <- read_rds(here("data", "df_power_of_10.Rds")) %>%
select(!type)
################################################################################
# IDs of runners that have completed at least 1 marathon                       #
################################################################################
df_power_of_10 %>%
filter(distance == 42194.988) %>%
pull(id) %>%
unique() -> ID_run_marathon
################################################################################
# IDs of runners that initially enough training points                         #
################################################################################
df_power_of_10 %>%
filter(id %in% ID_run_marathon & distance != 42194.988 & distance >= 400) %>%
group_by(id) %>%
summarise(n_dis = n_distinct(distance),
n_train = n()) %>%
filter(n_dis >= 3 & n_train >= 3) %>%
pull(id) %>%
unique() -> ID_enough_train_init
################################################################################
# Data frame containing the number of marathons each runner has completed      #
################################################################################
df_power_of_10 %>%
filter(id %in% ID_enough_train_init) %>%
filter(distance == 42194.988) %>%
group_by(id) %>%
summarise(n_marathons = n()) -> df_n_marathons
################################################################################
# Data frame that only contains marathons -- i.e. Testing dataset              #
################################################################################
df_power_of_10 %>%
filter(distance == 42194.988 & id %in% ID_enough_train_init) %>%
mutate(date_lb = date %m-% months(4)) %>%
group_by(id) %>%
mutate(marathon_n = row_number(),
updated_id = paste0(id,"_",marathon_n)) %>%
ungroup() %>%
select(id,updated_id,marathon_n,date,date_lb,distance,duration,power) %>%
rename(date_up = date) -> marathons_only
# data_lb = The date 4 months prior to the testing marathon
# data_up = The date of the testing marathon
# Both of these will be used to filter out data points that
# will not be included in the training dataset.
###############################################################################
# Data frame that only contains observations from athletes with enough intial #
# training data                                                               #
###############################################################################
df_power_of_10 %>%
filter(id %in% ID_enough_train_init & distance >= 400)  -> training_data_init
###############################################################################
# For each athlete, create a dataset that contains duplicated training        #
# observations depending on the number of marathons completed by the athlete. #
# Each marathon will be treated essentially as it's own athlete. And the      #
# PL model will be fit to data from up to 4 months prior.                     #
###############################################################################
duplicated_training_data <- tibble()
re_wrangle <- TRUE
if(re_wrangle == TRUE){
for(i in 1:length(ID_enough_train_init)){
ID <- ID_enough_train_init[i]
n_marathons <- df_n_marathons %>%
filter(id == ID) %>%
pull(n_marathons)
df_i <- training_data_init %>%
filter(id == ID)
aux_marathon_n <- rep(1:n_marathons, each = nrow(df_i))
duplicated_training_data_aux <- df_i %>%
slice(rep(1:n(), times = n_marathons)) %>%
cbind(marathon_n = aux_marathon_n) %>%
mutate(updated_id = paste0(id, "_", marathon_n))
duplicated_training_data <- rbind(duplicated_training_data,duplicated_training_data_aux)
}
saveRDS(duplicated_training_data,here("data","duplicated_training_data.RDS"))
}else{
duplicated_training_data <- readRDS(here("data","duplicated_training_data.RDS"))
}
###############################################################################
# Getting the IDs for the athletes that now have enough training data within  #
# the 4 months prior to the testing marathon                                  #
###############################################################################
marathons_only %>%
select(updated_id,date_lb,date_up) %>%
left_join(duplicated_training_data, by = c("updated_id"), multiple = "all") %>%
mutate(is_in = if_else(date >= date_lb & date < date_up,1,0)) %>%
filter(is_in == 1 & distance >= 400) %>%
group_by(updated_id) %>%
summarise(n_dis = n_distinct(distance),
n_train = n()) %>%
filter(n_dis >= 3 & n_train >= 3) %>%
pull(updated_id) %>%
unique() -> ID_final
###############################################################################
# Creating the final training dataset                                         #
###############################################################################
marathons_only %>%
select(updated_id,date_lb,date_up, duration, power, marathon_n) %>%
rename(act_duration = duration,
act_velocity = power) %>%
left_join(duplicated_training_data, by = c("updated_id","marathon_n"), multiple = "all") %>%
mutate(is_in = if_else(date >= date_lb & date < date_up,1,0)) %>%
filter(is_in == 1 & updated_id %in% ID_final) -> training_data
###############################################################################
# Get the Endurance parameter for the PL model                                #
###############################################################################
get_E <- function(power,durations){
data_pl <- tibble(power = power, durations = durations)
pl_lr <- lm(data = data_pl, I(log(power)) ~ I(log(durations)))
b <- 1 - as.numeric(-coef(pl_lr)[2])
return(b)
}
###############################################################################
# Get the Sprint parameter for the PL model                                   #
###############################################################################
get_S <- function(power,durations){
data_pl <- tibble(power = power, durations = durations)
pl_lr <- lm(data = data_pl, I(log(power)) ~ I(log(durations)))
a <- as.numeric(exp(coef(pl_lr)[1]))
return(a)
}
###############################################################################
# Creating a data frame of the actual finishing time for each marathon        #
###############################################################################
marathons_only %>%
select(updated_id,duration) %>%
rename(mar_fin_time = duration) -> marathon_fin_time_df
###############################################################################
# Calculating the error for each marathon                                     #
###############################################################################
training_data %>%
group_by(updated_id) %>%
mutate(weighting = 1/as.numeric(date_up - date)) %>%
summarise(E = get_E(power = power, durations = duration),
S = get_S(power = power, durations = duration)) %>%
mutate(mar_fin = (42194.988/S)^(1/(E))) %>%
left_join(marathon_fin_time_df, by = "updated_id") %>%
mutate(error = abs(mar_fin - mar_fin_time)/ mar_fin_time) -> error_df
###############################################################################
# Average error for N =  1697                                                 #
###############################################################################
mean(error_df$error, na.rm = TRUE)
df_power_of_10 %>%
filter(id %in% ID_run_marathon & distance <= 400) %>%
pull(id) %>%
unique() %>%
length()
df_power_of_10 %>%
filter(id %in% ID_run_marathon & distance < 400) %>%
pull(id) %>%
unique() %>%
length()
training_data  %>%
filter( distance < 400) %>%
pull(updated_id) %>%
unique() %>%
length()
re_wrangle <- FALSE
mean(error_df$error, na.rm = TRUE)
################################################################################
# Preamble                                                                     #
################################################################################
library("here")
library("tidyverse")
library("janitor")
my_theme <- theme_classic(base_size = 10)
theme_set(my_theme)
# Colours
col_hyp <- "#F8766D"
col_pow <- "#00BFC4"
################################################################################
# Mitchell - Data                                                              #
################################################################################
mitchell_phys <- read_csv(here("data","mitchell_data_phys.csv")) %>%
clean_names() %>%
rename(id = participant_id)
################################################################################
# Preamble                                                                     #
################################################################################
library("here")
library("tidyverse")
library("janitor")
my_theme <- theme_classic(base_size = 10)
theme_set(my_theme)
# Colours
col_hyp <- "#F8766D"
col_pow <- "#00BFC4"
################################################################################
# Mitchell - Data                                                              #
################################################################################
mitchell_phys <- read_csv(here("data","mitchell_data_phys.csv")) %>%
clean_names() %>%
rename(id = participant_id)
IDs <- mitchell_phys %>%
pull(id) %>%
unique()
apo_tib <- mitchell_phys %>%
select(id,apo) %>% rename(power = apo) %>%
mutate(durations = 5,
effort_id = 6)
mitchell_pow <- read_csv(here("data","mitchell_data_pow.csv")) %>%
clean_names() %>%
rename(durations = duration) %>%
cbind(effort_id = rep(1:5, each = length(IDs))) %>%
rbind(apo_tib) %>%
filter(!(id == 8 & effort_id %in% c(3,4)))
# Efforts 3 and 4 for athlete 8 do not appear to be maximal, hence the reason
# the study re-tested 2 times.
################################################################################
# Mitchell - Fitting the power-law model to each athlete                       #
################################################################################
fit_pow_lr_pow <- function(data_pl,t){
pl_lr <- lm(data = data_pl, I(log(power)) ~ I(log(durations)))
a <- as.numeric(exp(coef(pl_lr)[1]))
b <- as.numeric(-coef(pl_lr)[2])
pl_power <- a/(t^b)
return(list(S = a,
E = 1-b,
duration = t,
power = pl_power))
}
aux_IDs <- mitchell_pow %>%
pull(id) %>%
unique()
pl_tib <- tibble()
pl_tib_plot <- tibble()
t_p <- 1:(max(mitchell_pow$durations, na.rm = TRUE) * 1.1)
for (i in aux_IDs) {
data_pl_i <- mitchell_pow %>%
filter(id == i  & durations >= 120 & durations <= 1200)
pl_list_i <- fit_pow_lr_pow(data_pl = data_pl_i, t = t_p)
pl_tib_aux <- tibble(id = i,
S = pl_list_i$S,
E = pl_list_i$E)
pl_tib <- rbind(pl_tib,pl_tib_aux)
pl_tib_plot_aux <- tibble(id = i,
durations = pl_list_i$duration,
power = pl_list_i$power)
pl_tib_plot <- rbind(pl_tib_plot,pl_tib_plot_aux)
}
################################################################################
# Mitchell - Fitting the critical-power model to each athlete                  #
################################################################################
fit_cp_lr_pow <- function(data_cp,t){
cp_lr <- lm(data = data_cp, power ~ I(1/durations))
w_prime <- cp_lr$coefficients["I(1/durations)"]
cp <- cp_lr$coefficients["(Intercept)"]
cp_power <- w_prime/t + cp
return(list(cp = cp,
w_prime = w_prime,
duration = t,
power = cp_power))
}
aux_IDs <- mitchell_pow %>%
pull(id) %>%
unique()
cp_tib <- tibble()
cp_tib_plot <- tibble()
t_p <- 1:(max(mitchell_pow$durations, na.rm = TRUE) * 1.1)
for (i in aux_IDs) {
data_cp_i <- mitchell_pow %>%
filter(id == i & durations >= 120 & durations <= 900)
cp_list_i <- fit_cp_lr_pow(data_cp = data_cp_i, t = t_p)
cp_tib_aux <- tibble(id = i,
cp = cp_list_i$cp,
w_prime = cp_list_i$w_prime)
cp_tib <- rbind(cp_tib,cp_tib_aux)
cp_tib_plot_aux <- tibble(id = i,
durations = cp_list_i$duration,
power = cp_list_i$power)
cp_tib_plot <- rbind(cp_tib_plot,cp_tib_plot_aux)
}
par_tib <- pl_tib %>%
left_join(cp_tib, by = "id")
################################################################################
# Mitchell - Correlation plot 30 minute power                                  #
################################################################################
corr_plot_tib <- mitchell_phys %>%
left_join(pl_tib, by = "id") %>%
mutate(pl_30 = S/((60*30)^(1-E)))
corr_plot_tib_test <-  corr_plot_tib %>%
select(id,pl_30,
percent_type_1,percent_type_2,
mhc_i_csa,mhc_ii_csa,
c_density_mm2,c_f,
caf_mhc_i,caf_mhc_ii) %>%
gather(key = "var", value = "value", -c("id","pl_30")) %>%
group_by(var) %>%
mutate(correlation = cor(value,pl_30,use="complete.obs"),
p_val = cor.test(value,pl_30,use="complete.obs")$p.value,
x_pos =  (max(value, na.rm = TRUE) - min(value, na.rm = TRUE)) * 0.8 + min(value, na.rm = TRUE),
y_pos =  415, #max(pl_30, na.rm = TRUE) * 1.35,
lab = if_else(round(p_val,3) < 0.001,paste("r =", round(correlation, 3),"\np < 0.001") ,
paste("r =", round(correlation, 3),"\np =", round(p_val,3)))) %>%
mutate(var = recode(var,
percent_type_1 = "Type I fibre %",
percent_type_2 = "Type II fibre %",
mhc_i_csa = "CSA type I (\u03BCm^-2)",
mhc_ii_csa = "CSA type II (\u03BCm^-2)",
c_density_mm2 = "Capillary density (cap.mm^-2)",
c_f = "Capillary to fibre ratio",
caf_mhc_i = "CC type I",
caf_mhc_ii = "CC type II"))
var_levels <- corr_plot_tib_test %>%
pull(var) %>%
unique()
corr_plot_tib_test %>%
ggplot(aes(x = value, y = pl_30)) +
geom_point(aes()) +
geom_text(mapping = aes(x = x_pos, y = y_pos, label = lab), size = 2.5) +
geom_smooth(method = "lm", formula = 'y~x', se = FALSE) +
labs(x = "", y = "30-min. max. power (as predicted by the power-law model)") +
scale_colour_manual(values = c("black", "red"), guide = "none")+
facet_wrap(~ factor(var, levels = var_levels), scales = "free_x", ncol = 2, strip.position = "bottom") +
coord_cartesian(ylim = c(150, 435)) +
theme(strip.background = element_blank(), strip.placement = "outside") -> pl_30_cor
ggsave(here("figures","pl_30_par_cor_plot.png"), plot = pl_30_cor, dpi = 3200, width = 0.5 * 8, height =  0.5 * 12)
################################################################################
# Mitchell - Correlation plot for E                                            #
################################################################################
corr_plot_tib_test <-  corr_plot_tib %>%
select(id,E,
percent_type_1,percent_type_2,
mhc_i_csa,mhc_ii_csa,
c_density_mm2,c_f,
caf_mhc_i,caf_mhc_ii) %>%
gather(key = "var", value = "value", -c("id","E")) %>%
group_by(var) %>%
mutate(correlation = cor(value,E,use="complete.obs"),
p_val = cor.test(value,E,use="complete.obs")$p.value,
x_pos =  (max(value, na.rm = TRUE) - min(value, na.rm = TRUE)) * 0.85 + min(value, na.rm = TRUE),
y_pos =  0.92,
lab = if_else(round(p_val,3) < 0.001,paste("r =", round(correlation, 3),"\np < 0.001") ,
paste("r =", round(correlation, 3),"\np =", round(p_val,3)))) %>%
mutate(var = recode(var,
percent_type_1 = "Type I fibre %",
percent_type_2 = "Type II fibre %",
mhc_i_csa = "CSA type I (\u03BCm^-2)",
mhc_ii_csa = "CSA type II (\u03BCm^-2)",
c_density_mm2 = "Capillary density (cap.mm^-2)",
c_f = "Capillary to fibre ratio",
caf_mhc_i = "CC type I",
caf_mhc_ii = "CC type II"))
var_levels <- corr_plot_tib_test %>%
pull(var) %>%
unique()
corr_plot_tib_test  %>%
ggplot(aes(x = value, y = E)) +
geom_point() +
geom_text(mapping = aes(x = x_pos, y = y_pos, label = lab), size = 2.5) +
geom_smooth(method = "lm", formula = 'y~x', se = FALSE) +
labs(x = "", y = "Endurance parameter, E, of the power-law model") +
facet_wrap(~ factor(var, levels = var_levels), scales = "free_x", ncol = 2,strip.position = "bottom") +
coord_cartesian(ylim = c(0.77,0.94)) +
theme(strip.background = element_blank(), strip.placement = "outside") -> E_cor
ggsave(here("figures","Endurance_par_cor_plot.png"), plot = E_cor, dpi = 3200, width = 0.5 * 8, height = 0.5 * 12)
